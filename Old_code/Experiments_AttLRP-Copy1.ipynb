{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b1310e-82d5-4cb7-b18a-a6e6dffef139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxt.models.llama import LlamaForCausalLM, attnlrp\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from lxt.models.llama import LlamaForCausalLM, attnlrp\n",
    "\n",
    "# load model\n",
    "model_id = \"Local-Meta-Llama-3.2-1B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,device_map=\"cpu\")\n",
    "\n",
    "\n",
    "# apply LXT to the model\n",
    "lxt_model = attnlrp.register(model)\n",
    "\n",
    "# (optionally enable gradient checkpointing)\n",
    "lxt_model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73271097-ec64-4c54-98a7-ba0f3e4e7f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): IdentityRule(\n",
       "            (module): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4993e90-c5b1-4c5a-9813-21ee8ac3a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=None\n",
    "def hook_fn(module, input, output):\n",
    "    global embeddings\n",
    "    output.requires_grad_(True)\n",
    "    output.retain_grad() \n",
    "    embeddings=output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13d036d-d842-4e83-9fb1-3bcb93ce64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = lxt_model.model.embed_tokens.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2b0e4b-407d-4fc1-942c-52b414859919",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "prompt = \"\"\"We have an apple tree which has this year very many\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14ee3a5-1222-499a-8a27-c604f15ca98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab37f39b-0824-416d-ae16-498f70df07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "output_logits = lxt_model(**input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe6c82a-c94d-4131-b748-5083ecb2b6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0028,  0.0033, -0.0099,  ..., -0.0018,  0.0008,  0.0007],\n",
       "         [ 0.0167, -0.0031,  0.0334,  ...,  0.0137, -0.0065, -0.0067],\n",
       "         [ 0.0129,  0.0142,  0.0179,  ...,  0.0115, -0.0282, -0.0303],\n",
       "         ...,\n",
       "         [-0.0004, -0.0304,  0.0098,  ...,  0.0122, -0.0254,  0.0058],\n",
       "         [-0.0056, -0.0073,  0.0315,  ..., -0.0026, -0.0052, -0.0220],\n",
       "         [ 0.0009,  0.0189,  0.0210,  ..., -0.0032, -0.0216,  0.0013]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd847e9-6bcd-44f8-b64b-dab65dd89ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# select token to explain\n",
    "select_class_logit = output_logits.logits[0, -1, :].max()\n",
    "\n",
    "# run backward\n",
    "select_class_logit.backward(select_class_logit)\n",
    "\n",
    "# obtain relevances by summing over embedding dimension i.e. keeping sequence dimension\n",
    "relevance = embeddings.grad.float().sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eeaf4a-edc5-43c9-9552-777e21535074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530d0064-fb07-4a6e-8854-6ae302c545f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is XeTeX, Version 3.141592653-2.6-0.999995 (TeX Live 2023/Debian) (preloaded format=xelatex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./heatmap.tex\n",
      "LaTeX2e <2023-11-01> patch level 1\n",
      "L3 programming layer <2024-01-22>\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/standalone/standalone.cls\n",
      "Document Class: standalone 2022/10/10 v1.3b Class to compile TeX sub-files stan\n",
      "dalone\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/shellesc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/ifluatex.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/iftex.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/keyval.tex))))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/standalone/standalone.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2023/05/17 v1.4n Standard LaTeX document class\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/size10.clo)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/mathcolor.ltx))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/dvipsnam.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3backend/l3backend-xetex.def)\n",
      "\n",
      "LaTeX Warning: Unused global option(s):\n",
      "    [arwidth].\n",
      "\n",
      "No file heatmap.aux.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd) [1] (./heatmap.aux) )\n",
      "Output written on ./heatmap.pdf (1 page).\n",
      "Transcript written on ./heatmap.log.\n",
      "PDF file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "from lxt.utils import pdf_heatmap, clean_tokens\n",
    "\n",
    "# convert token ids to strings\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.input_ids[0])\n",
    "\n",
    "# removes the '_' character of tokens\n",
    "tokens = clean_tokens( [token.replace('ƒ†', '‚ñÅ') for token in tokens])\n",
    "\n",
    "# normalize relevance between [-1, 1] for plotting\n",
    "\n",
    "relevance = relevance / relevance.abs().max()\n",
    "\n",
    "# generate PDF file\n",
    "pdf_heatmap(tokens, relevance[0], path='heatmap.pdf', backend='xelatex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0983495b-d1ab-4b1d-884d-8c1c493d0752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5448,  1.0000,  0.2069,  0.1789, -0.3949, -0.1024,  0.0661,  0.0639,\n",
       "         -0.0050,  0.0130,  0.1569, -0.1251]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadb3c7b-f401-42cf-aba1-aa692fc26980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is XeTeX, Version 3.141592653-2.6-0.999995 (TeX Live 2023/Debian) (preloaded format=xelatex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./heatmap.tex\n",
      "LaTeX2e <2023-11-01> patch level 1\n",
      "L3 programming layer <2024-01-22>\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/standalone/standalone.cls\n",
      "Document Class: standalone 2022/10/10 v1.3b Class to compile TeX sub-files stan\n",
      "dalone\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/shellesc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/ifluatex.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/iftex.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/keyval.tex))))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/standalone/standalone.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2023/05/17 v1.4n Standard LaTeX document class\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/size10.clo)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/mathcolor.ltx))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/graphics/dvipsnam.def)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3backend/l3backend-xetex.def)\n",
      "\n",
      "LaTeX Warning: Unused global option(s):\n",
      "    [arwidth].\n",
      "\n",
      "No file heatmap.aux.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)\n",
      "Underfull \\hbox (badness 1910) in paragraph at lines 9--9\n",
      "[][][][][][][] [][][][][][][][][][][][] [][][][][][] [][][][][][][][][][][][] [\n",
      "][][][][][][][][][][][] [][][][][][] [][][][][][][][][][][][][][][][][][] [][][\n",
      "][][][] [][][][][][]\n",
      "[1] (./heatmap.aux) )\n",
      "(see the transcript file for additional information)\n",
      "Output written on ./heatmap.pdf (1 page).\n",
      "Transcript written on ./heatmap.log.\n",
      "PDF file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from lxt.models.llama import attnlrp, LlamaForCausalLM\n",
    "from lxt.utils import pdf_heatmap, clean_tokens\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "# apply AttnLRP rules\n",
    "attnlrp.register(model)\n",
    "\n",
    "prompt = \"\"\"\\\n",
    "Context: Mount Everest attracts many climbers, including highly experienced mountaineers. There are two main climbing routes, one approaching the summit from the southeast in Nepal (known as the standard route) and the other from the north in Tibet. While not posing substantial technical climbing challenges on the standard route, Everest presents dangers such as altitude sickness, weather, and wind, as well as hazards from avalanches and the Khumbu Icefall. As of November 2022, 310 people have died on Everest. Over 200 bodies remain on the mountain and have not been removed due to the dangerous conditions. The first recorded efforts to reach Everest's summit were made by British mountaineers. As Nepal did not allow foreigners to enter the country at the time, the British made several attempts on the north ridge route from the Tibetan side. After the first reconnaissance expedition by the British in 1921 reached 7,000 m (22,970 ft) on the North Col, the 1922 expedition pushed the north ridge route up to 8,320 m (27,300 ft), marking the first time a human had climbed above 8,000 m (26,247 ft). The 1924 expedition resulted in one of the greatest mysteries on Everest to this day: George Mallory and Andrew Irvine made a final summit attempt on 8 June but never returned, sparking debate as to whether they were the first to reach the top. Tenzing Norgay and Edmund Hillary made the first documented ascent of Everest in 1953, using the southeast ridge route. Norgay had reached 8,595 m (28,199 ft) the previous year as a member of the 1952 Swiss expedition. The Chinese mountaineering team of Wang Fuzhou, Gonpo, and Qu Yinhua made the first reported ascent of the peak from the north ridge on 25 May 1960. \\\n",
    "Question: How high did they climb in 1922? According to the text, the 1922 expedition reached 8,\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).input_ids.to(model.device)\n",
    "input_embeds = model.get_input_embeddings()(input_ids)\n",
    "\n",
    "output_logits = model(inputs_embeds=input_embeds.requires_grad_(), use_cache=False).logits\n",
    "max_logits, max_indices = torch.max(output_logits[0, -1, :], dim=-1)\n",
    "\n",
    "max_logits.backward(max_logits)\n",
    "relevance = input_embeds.grad.float().sum(-1).cpu()[0]\n",
    "\n",
    "# normalize relevance between [-1, 1] for plotting\n",
    "relevance = relevance / relevance.abs().max()\n",
    "\n",
    "# remove '_' characters from token strings\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "tokens = clean_tokens(tokens)\n",
    "\n",
    "pdf_heatmap(tokens, relevance, path='heatmap.pdf', backend='xelatex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca6bd65-82b7-442e-b2ee-5fe1fcb4693d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3174e-01,  5.1772e-03,  3.0630e-03,  3.5403e-03,  3.4851e-03,\n",
       "         4.6443e-03,  1.7936e-03,  1.2930e-03,  1.6109e-03,  2.7891e-03,\n",
       "         2.4576e-03, -1.2220e-03,  1.6182e-03,  1.8135e-03,  1.7418e-03,\n",
       "         1.8228e-03,  2.4520e-03,  2.1099e-03,  1.3054e-03,  1.8292e-03,\n",
       "         1.8697e-03,  1.9619e-03,  1.3322e-03,  2.8636e-03,  1.9916e-03,\n",
       "         2.3866e-03,  1.3190e-03,  3.8806e-04,  2.0783e-03,  1.4046e-03,\n",
       "         2.2964e-03,  1.1245e-03,  1.6831e-03,  1.2276e-03,  1.6945e-03,\n",
       "         1.6947e-03,  2.0713e-03,  1.9290e-03,  1.8058e-03,  1.4155e-03,\n",
       "         5.7857e-04,  1.0910e-03,  9.0939e-04,  1.1654e-03,  1.0153e-03,\n",
       "         1.3953e-03,  1.2950e-03,  1.0104e-03,  4.3651e-04,  1.0666e-03,\n",
       "         9.2651e-04,  1.2155e-03,  1.7105e-03,  1.7831e-03,  1.5012e-03,\n",
       "         2.8594e-03,  8.0783e-04,  1.1731e-03,  1.0717e-03,  1.2485e-03,\n",
       "         1.2572e-03,  1.7750e-03,  2.7867e-03,  1.9827e-03,  1.4460e-03,\n",
       "         1.2466e-03,  1.3778e-03,  9.9238e-04,  1.1164e-03,  1.4910e-03,\n",
       "         3.8431e-04,  3.9903e-03,  3.7186e-03,  2.0442e-03,  1.5315e-03,\n",
       "         2.5500e-03,  1.3632e-03,  1.3429e-03,  2.7390e-03,  2.3821e-03,\n",
       "         1.9561e-03,  1.2788e-03,  1.0556e-03,  1.2593e-03,  6.9663e-04,\n",
       "         1.5236e-03,  1.2427e-03,  1.2242e-03,  1.6036e-03,  1.1597e-03,\n",
       "         1.2827e-03,  1.1998e-03,  6.3096e-04,  1.2102e-03,  1.4323e-03,\n",
       "         8.8207e-04,  1.1894e-03,  1.5060e-03,  1.1474e-03,  1.3934e-03,\n",
       "         7.3677e-04,  2.1143e-03,  1.3786e-03,  1.2304e-03,  1.0412e-03,\n",
       "         7.5173e-04,  4.7634e-03,  2.3477e-03,  2.2805e-03,  1.8116e-03,\n",
       "         1.2793e-03,  1.2012e-03,  1.3696e-03, -1.0170e-03, -2.0217e-03,\n",
       "         3.0047e-05,  5.8642e-04, -7.8700e-05,  6.9139e-04,  4.9937e-04,\n",
       "         2.1838e-03,  1.5432e-03,  8.1152e-04,  1.7985e-03,  2.8278e-03,\n",
       "         2.8540e-03,  4.3400e-03,  1.2677e-03,  2.3826e-04, -2.2306e-05,\n",
       "         1.3876e-04,  1.4783e-04,  1.2512e-03,  1.4734e-03,  1.8841e-03,\n",
       "         1.0679e-03,  2.9268e-03,  1.9646e-03,  1.3373e-03,  8.0006e-04,\n",
       "         5.7783e-04,  6.7378e-04,  1.0034e-03,  2.0059e-03,  1.2069e-03,\n",
       "         1.8725e-03,  9.8968e-04,  4.4114e-03,  1.7963e-03, -1.0961e-03,\n",
       "         2.3263e-03,  2.8753e-03,  2.1224e-03,  3.5327e-03,  4.0954e-03,\n",
       "         4.2045e-03,  1.1304e-03,  1.1444e-03,  1.7642e-03,  6.7407e-04,\n",
       "         1.5295e-03,  7.5635e-04,  1.7549e-03,  3.4214e-03,  2.3902e-03,\n",
       "         2.3045e-03,  1.4734e-03,  7.9347e-03,  1.4952e-03,  3.3175e-03,\n",
       "         1.3029e-03,  1.6983e-03,  1.2365e-03,  2.0842e-04,  2.2866e-03,\n",
       "         1.6724e-03,  1.7780e-03,  7.6227e-04,  1.3650e-03,  2.0879e-03,\n",
       "         2.2101e-03,  1.2106e-03,  1.3905e-03,  1.3133e-05,  1.6236e-03,\n",
       "         2.0050e-03,  1.3659e-03,  1.5616e-03,  2.6593e-03,  1.7094e-03,\n",
       "         1.5233e-03,  7.2445e-03,  3.4173e-03,  7.1478e-03,  3.8449e-03,\n",
       "         2.6845e-03,  1.2056e-03,  2.9599e-03,  1.8402e-03,  1.8337e-03,\n",
       "         4.4549e-04,  7.7008e-03,  7.1369e-03,  2.8471e-03,  2.3050e-03,\n",
       "         3.3281e-03,  3.3838e-03,  8.9447e-03,  3.6406e-03,  1.7396e-03,\n",
       "         3.0574e-03,  4.3867e-03,  1.5255e-03,  2.6725e-03,  3.4354e-03,\n",
       "         5.8319e-03,  5.3259e-03,  5.5055e-02,  4.1831e-02,  4.6737e-02,\n",
       "         6.5193e-02,  4.7393e-02,  2.7263e-02,  2.3539e-02,  1.8678e-02,\n",
       "         3.5902e-03, -8.5198e-04,  6.1668e-04,  6.4685e-03,  5.6387e-03,\n",
       "         6.3074e-03,  4.1392e-03,  5.0445e-03,  1.9809e-02,  5.2211e-03,\n",
       "         1.4616e-03,  5.3042e-03,  4.0089e-03,  6.2244e-03,  5.3981e-03,\n",
       "         2.7498e-03,  2.2397e-03,  4.8541e-03,  6.6722e-03,  5.0604e-03,\n",
       "         2.3826e-03,  1.1166e-02,  4.9070e-03,  1.1254e-02,  2.3147e-03,\n",
       "         5.3700e-03, -1.7530e-03,  2.4566e-02,  3.5630e-02,  9.7962e-02,\n",
       "         3.7461e-01,  3.1538e-01,  6.2375e-01,  4.2057e-02,  2.9278e-02,\n",
       "         2.6408e-02,  3.1802e-03,  1.6038e-03,  2.7060e-03,  4.3364e-03,\n",
       "         1.2043e-02,  1.7763e-03,  2.0287e-03,  4.1376e-03,  2.2565e-02,\n",
       "         3.6062e-03,  1.7756e-03,  1.4093e-03,  4.4595e-04,  1.6229e-03,\n",
       "         1.9128e-03,  2.4961e-03,  2.1800e-03,  1.2634e-03,  6.1279e-05,\n",
       "         6.8778e-03, -3.9023e-03, -1.1184e-02,  7.2528e-03,  6.9265e-02,\n",
       "         9.2819e-03,  4.6591e-03,  3.4234e-03, -8.8705e-05, -5.9727e-04,\n",
       "         9.7661e-05,  7.1599e-04,  1.2804e-03,  7.7725e-04,  8.3736e-04,\n",
       "         2.0114e-04,  1.2096e-02,  9.5576e-04, -6.2405e-04, -2.1709e-03,\n",
       "        -1.5722e-03,  2.7189e-04, -3.2845e-03, -5.8061e-04,  1.5785e-03,\n",
       "         8.5661e-04,  5.0133e-04,  5.0267e-04,  2.5550e-04, -3.1428e-04,\n",
       "         4.5518e-04,  1.2597e-04,  1.8872e-04,  1.1900e-03,  1.3752e-03,\n",
       "         4.2764e-04,  4.6392e-04,  2.5707e-04, -5.4622e-04,  2.2191e-03,\n",
       "        -4.5238e-06, -2.8678e-03,  8.9290e-04,  1.1891e-03,  1.1590e-03,\n",
       "         5.7774e-04,  9.2765e-04,  5.7367e-04, -9.9482e-05, -7.7958e-04,\n",
       "         5.5974e-04,  3.5263e-04,  2.2995e-03,  1.6038e-04, -9.9000e-03,\n",
       "        -3.2562e-02,  2.2744e-02,  1.0761e-03,  4.9733e-04,  2.6646e-05,\n",
       "         4.8456e-04,  5.4933e-04,  5.2837e-04,  8.7981e-04,  1.2245e-03,\n",
       "         1.3575e-03,  3.5855e-04, -4.5036e-04,  5.9726e-04,  4.4623e-04,\n",
       "         2.7211e-04,  1.2437e-03,  4.0918e-03,  6.3930e-04,  5.1036e-04,\n",
       "         2.3919e-03,  7.2234e-04,  1.5299e-03,  5.3652e-04,  9.4244e-04,\n",
       "         8.7205e-04,  5.8685e-04,  9.1629e-04,  7.8448e-04,  4.8102e-04,\n",
       "        -1.1062e-04,  6.0156e-04,  6.3634e-04, -8.9169e-05,  1.1296e-03,\n",
       "         1.6110e-03,  1.7489e-03,  4.4732e-04,  1.8487e-04, -2.9401e-04,\n",
       "         6.5780e-04, -6.8081e-04, -4.6968e-04, -2.3856e-04, -5.1311e-04,\n",
       "        -2.0795e-03, -1.1069e-03,  7.7628e-04,  7.7544e-04,  8.4734e-04,\n",
       "         1.0241e-03,  7.5670e-04,  1.7652e-03,  1.4396e-03,  3.4198e-03,\n",
       "         1.0972e-03,  4.2199e-04,  4.3258e-04,  2.7544e-03,  1.3841e-02,\n",
       "         1.0895e-02,  2.6121e-02,  4.7315e-02,  4.0379e-02,  9.6551e-03,\n",
       "         5.0877e-03,  3.4860e-03,  1.9516e-03,  1.2938e-04,  1.2189e-03,\n",
       "         5.5010e-03,  2.0435e-03,  1.3389e-03,  9.2385e-04,  1.3933e-03,\n",
       "         4.9747e-03,  1.2099e-03,  1.1246e-03,  1.1580e-03,  6.7144e-04,\n",
       "         3.0691e-04,  3.1508e-04,  3.0180e-04,  1.7147e-04, -6.3012e-04,\n",
       "        -7.8542e-04,  5.1482e-04, -1.4564e-05, -3.6748e-04,  1.8265e-03,\n",
       "         1.6357e-03,  2.7282e-03,  2.4763e-03,  2.9106e-03,  2.0145e-03,\n",
       "         1.5754e-03,  1.1923e-03,  2.3552e-03,  1.5624e-03,  1.3170e-03,\n",
       "         8.7607e-04,  8.1832e-04,  8.9780e-04, -8.3693e-04,  1.6013e-03,\n",
       "         1.4925e-03, -1.5288e-03, -6.2356e-04, -4.8272e-05,  2.0505e-03,\n",
       "         6.4382e-04,  4.8397e-04,  7.7120e-04,  9.4982e-04,  5.9623e-04,\n",
       "         1.1900e-03,  2.0085e-03,  2.3011e-03,  2.7670e-03,  9.0953e-04,\n",
       "         6.0929e-04,  4.6150e-03,  1.4526e-03,  1.5061e-04,  1.3032e-03,\n",
       "        -1.0941e-06,  1.7754e-03,  8.3431e-04, -7.6797e-04,  9.8007e-04,\n",
       "         1.4532e-03,  3.4145e-03, -3.4940e-04,  1.8669e-03,  1.9827e-03,\n",
       "         2.7558e-03,  9.4964e-04,  1.0108e-02,  1.2751e-02,  1.0282e-02,\n",
       "         4.6305e-02,  7.0844e-02,  1.4407e-02,  6.0508e-03,  6.3343e-03,\n",
       "         2.1287e-03,  5.5270e-03,  5.3854e-04, -1.1121e-03, -1.3765e-04,\n",
       "         2.0521e-03, -1.5365e-02,  3.5693e-02,  6.8208e-02,  1.0121e-02,\n",
       "         1.0531e-02,  3.0824e-02,  3.1684e-02,  2.2097e-02,  7.5266e-03,\n",
       "        -1.5949e-03,  1.0883e-02, -8.4322e-03, -2.7355e-02,  9.7226e-03,\n",
       "         2.4979e-01,  4.0249e-01,  9.2184e-01,  1.0000e+00])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be74c6c-fc1b-4707-ace9-811ee7ea815e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
