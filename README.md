# **Minor Mathematical Mechanisms in Large Language Models**


## **Abstract**  

Large language models (LLMs) have transformed the field of natural language processing (NLP) by opening up a new learning paradigm, called in-context learning (ICL). Considerable work has been done to understand the underlying mechanisms driving ICL. However, no conclusive evidence has been found, and seemingly contradictory explanations have emerged.
In this work, we investigate two seemingly contrasting viewpoints on in-context learning given mathematical problems. Some studies have demonstrated that large language models can perform mathematical algorithms, such as solving linear regression. However, other work suggests that ICL primarily relies on simpler mechanisms, such as heuristics and similarity computations. This work aims to bridge the gap between these two viewpoints on in-context learning by investigating the extent to which mathematical algorithms influence the predictions of Llama 3.2 3B and Llama 3.1 8B.  In doing so, we provide indications that mathematical mechanisms exist in LLMs, vary across different mathematical problems, and have only limited influence on the predictions of the LLM.

The full report is given in "Report.pdf"


## **Notes on Code Usage**  
Some parts of this code were copied from other sources and generated using ChatGPT. Any directly copied code is explicitly noted within the code. However, sections written with ChatGPT's assistance are not specifically marked. **To avoid potential copyright issues, assume the entire code was developed with the help of ChatGPT.**  


## **Project Structure**  

### **Main Script**  
- **`main.py`** – Main program to run the experiments for Llama 3.2 3B. To run it for Llama 3.1 8B comment out lines 52-85 and use lines 86-126 instead.  

### **Task & Feature Relevance Analysis**  
- **`LLM_Tasks.py`** – Generates tasks for the LLMs.  
- **`Relevance_Maps.py`** – Computes relevance maps.  
- **`Prediction_Model.py`** – Runs and evaluates feature relevance in a model.  

### **Probing & Interventions**  
- **`Probing.py`** – Runs probing experiments.  
- **`Interventions.py`** – Performs intervention analysis.  
- **`Intervention_Model.py`** – Runs the model for intervention analysis.  

### **Results & Visualization**  
- **`Generate_Result_Graphics.py`** – Generates graphs.  

### **Helper Modules**  
- **`captum_helper.py`** – Overwrites Captum’s original code (fixing functionality issues).  
- **`Prediction_Helpers.py`** – Helper functions for `Relevance_Maps.py` and `Probing.py`.  
- **`TimeMeasurer.py`** – Provides time predictions for experiments.  

### **DAS Experiment** 
- **`DAS_Experiment.py`** – Main program to run the DAS experiments for Llama 3.2 3B for linear regression. To run it for manhattan distance change line 101 from "Task\_1=LLM\_Tasks.Regression\_Task\_Int(" to "Task\_1=LLM\_Tasks.Manhattan\_Distance\_Problem\_Int(".


### **Results** 
- **`results_Llama_3.2_3B`** – Includes all results for the Llama 3.2 3B as generated by "Generate_Result_Graphics.py"
- **`results_Llama_3.2_3B`** – Includes all results for the Llama 3.2 8B as generated by "Generate_Result_Graphics.py"   


## **Running the main Experiment Pipeline**  
To install the needed libraries, use:  
```bash
pip install -r Requirements.txt
```
To reproduce the results from my experiment pipeline in the report, run:  
```bash
python main.py
```


## **Running DAS Experiment**  
Install the needed libraries as in "Running the main Experiment Pipeline". Then, to reproduce the results from the DAS Experiment mentioned in the appendix, run:  
```bash
python DAS_Experiment.py
```
